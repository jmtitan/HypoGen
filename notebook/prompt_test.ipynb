{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a code snippet for hypothesis generation benchmark.\n",
    "\n",
    " - Base model\n",
    " - Hypothesis Generation inference Pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Hypothesis Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/mingyan_root/mingyan/jmtang/miniconda3/envs/llm/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading shards: 100%|██████████| 2/2 [01:07<00:00, 33.84s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:18<00:00,  9.29s/it]\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the language model pipeline\n",
    "llm = pipeline(\"text-generation\", model=\"Qwen/Qwen2.5-3B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_prompt = '''You are a social media expert. \n",
    "You are an expert at determining which tweet will be retweeted more. \n",
    "Given a set of observations, you want to generation hypotheses that will help predict which tweet out of a pair of tweets is more likely to be retweeted. \n",
    "Please note that the paired tweets are about the same content and are posted by the same user, so you should focus on the wording difference between the two tweets in each pair. \n",
    "Please propose {num_hypotheses} possible hypotheses. Please generate them in the format of 1. [hypothesis], 2. [hypothesis], ... {num_hypotheses}. [hypothesis]. \n",
    "Please make the hypotheses general enough to be applicable to new observations.\n",
    "We made some observations: \n",
    "{examples}\n",
    "Proposed hypotheses:'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': \"You are a social media expert. \\nYou are an expert at determining which tweet will be retweeted more. \\nGiven a set of observations, you want to generation hypotheses that will help predict which tweet out of a pair of tweets is more likely to be retweeted. \\nPlease note that the paired tweets are about the same content and are posted by the same user, so you should focus on the wording difference between the two tweets in each pair. \\nPlease propose <num_hypotheses> possible hypotheses. Please generate them in the format of 1. [hypothesis], 2. [hypothesis], ... <num_hypotheses>. [hypothesis]. \\nPlease make the hypotheses general enough to be applicable to new observations.\\nWe made some observations: \\n1. Tweet A: 'Check out our new product launch!' Tweet B: 'Don't miss our new product launch!'\\n2. Tweet A: 'Join us for a webinar on AI.' Tweet B: 'Sign up for our AI webinar now!'\\nProposed hypotheses: \\n1. [Tweet with action verb] is more likely to be retweeted than [Tweet without action verb].\\n2. [Tweet with strong emotion] is more likely to be retweeted than [Tweet without strong emotion].\\n3. [Tweet with personal benefit] is more likely to be retweeted than [Tweet without personal benefit].\\n4. [Tweet with urgency] is more likely to be retweeted than [Tweet without urgency].\\n5. [Tweet with specific details] is more likely to be retweeted than [Tweet without specific details]. 1. [Tweet with action verb] is more likely to be retweeted than [Tweet without action verb].\\n2. [Tweet with strong emotion] is more likely to be retweeted than [Tweet without strong emotion].\\n3. [Tweet with personal benefit] is more likely to be retweeted than [Tweet without personal benefit].\\n4. [Tweet with urgency] is more likely to be retweeted than [Tweet without urgency].\\n5. [Tweet\"}]\n"
     ]
    }
   ],
   "source": [
    "examples = \"1. Tweet A: 'Check out our new product launch!' Tweet B: 'Don't miss our new product launch!'\\n2. Tweet A: 'Join us for a webinar on AI.' Tweet B: 'Sign up for our AI webinar now!'\"\n",
    "num_hypotheses = 5\n",
    "formatted_prompt = gen_prompt.format(examples=examples, num_hypotheses=num_hypotheses)\n",
    "\n",
    "# Generate hypotheses\n",
    "hypotheses = llm(formatted_prompt, max_new_tokens=200, num_return_sequences=1)\n",
    "print(hypotheses[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Hypothesis inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_prompt = '''\n",
    "**INSTRUCT**\n",
    "You are a social media expert. \n",
    "Given a pair of tweets, you are asked to predict which tweet will be retweeted more. \n",
    "Please note that the paired tweets are about the same content and are posted by the same user, so you should focus on the wording difference between the two tweets. \n",
    "From past experiences, you learned a pattern. Now, at each time, you should apply a learned pattern to a pair of tweets and determine which one will get more retweets. \n",
    "Given the pattern you learned above, predict which one of the two tweets will get more retweets. \n",
    "Think step by step. \n",
    "First step: Think about if the pattern can be applied to the tweets. \n",
    "Second step: Analyze the textual difference between the two tweets. \n",
    "Third step: Based on the pattern, which tweet is more likely to get more retweets? \n",
    "Final step: Give your final answer in the format of Final answer: the _ tweet where _ is either first or second. \n",
    "\n",
    "**INPUT**\n",
    "Our learned pattern: {hypothesis_high_reward}\n",
    "The first tweet: {first_tweet} \n",
    "The second tweet: {second_tweet} \n",
    "\n",
    "**OUTPUT**\n",
    "Final answer:'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': '\\n**INSTRUCT**\\nYou are a social media expert. \\nGiven a pair of tweets, you are asked to predict which tweet will be retweeted more. \\nPlease note that the paired tweets are about the same content and are posted by the same user, so you should focus on the wording difference between the two tweets. \\nFrom past experiences, you learned a pattern. Now, at each time, you should apply a learned pattern to a pair of tweets and determine which one will get more retweets. \\nGiven the pattern you learned above, predict which one of the two tweets will get more retweets. \\nThink step by step. \\nFirst step: Think about if the pattern can be applied to the tweets. \\nSecond step: Analyze the textual difference between the two tweets. \\nThird step: Based on the pattern, which tweet is more likely to get more retweets? \\nFinal step: Give your final answer in the format of Final answer: the _ tweet where _ is either first or second. \\n\\n**INPUT**\\nOur learned pattern: [Tweet with strong emotion] is more likely to be retweeted than [Tweet without strong emotion]\\nThe first tweet: Derek Carr: \"I\\'m the biggest Fresno St fan there is … [BCS] would be the coolest thing ever.\" My story from Fresno: http://t.co/3ZeLnut0qq \\nThe second tweet: PM RT: My column from Fresno State, the aspiring Cinderella that no one outside of Fresno seems to embrace. http://t.co/3ZeLnut0qq\\n\\n**OUTPUT**\\nFinal answer: second\\nStep 1: The pattern we have learned suggests that tweets with strong emotion are more likely to be retweeted than those without strong emotion.\\nStep 2: Analyzing the tweets, we see that:\\n- First tweet: This tweet expresses a strong sentiment through its use of emotional language (\"the biggest Fresno St fan there is\", \"would be the coolest thing ever\"). It also includes a personal anecdote.\\n- Second tweet: This tweet has a more neutral tone. While it mentions Fresno State, the language used is less emotional and lacks the personal detail of the first tweet.\\nStep 3: Based on the learned pattern, the second tweet (second tweet) is more likely to be retweeted as it aligns with the pattern of being less emotionally charged and lacking the strong emotional content that the pattern suggests will lead to more retweets.\\nStep 4: Therefore, the final prediction is that the second tweet will get more retweets. Final answer: second Tweet. **INSTRUCT'}]\n"
     ]
    }
   ],
   "source": [
    "learn_hyp = '[Tweet with strong emotion] is more likely to be retweeted than [Tweet without strong emotion]'\n",
    "first_tweet = '''Derek Carr: \"I'm the biggest Fresno St fan there is … [BCS] would be the coolest thing ever.\" My story from Fresno: http://t.co/3ZeLnut0qq'''\n",
    "second_tweet = 'PM RT: My column from Fresno State, the aspiring Cinderella that no one outside of Fresno seems to embrace. http://t.co/3ZeLnut0qq'\n",
    "formatted_prompt = infer_prompt.format(hypothesis_high_reward=learn_hyp, first_tweet=first_tweet, second_tweet=second_tweet)\n",
    "\n",
    "# Generate hypotheses\n",
    "hypotheses = llm(formatted_prompt, \n",
    "    max_new_tokens=200, \n",
    "    num_return_sequences=1,\n",
    "    temperature=0.9, \n",
    "    do_sample=True)\n",
    "print(hypotheses[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 2 in 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''## INSTRUCTION\n",
    "You are a social media expert. Your task has two parts:\n",
    "\n",
    "### Part 1: Hypothesis Generation\n",
    "Given a set of tweet observations, you will generate hypotheses that are useful for predicting which tweet out of a pair will be retweeted more.\n",
    "- Each tweet pair is posted by the same user and contains similar content with slight wording differences.\n",
    "- Focus on these wording differences.\n",
    "- Please generate 1 hypotheses in the format:\n",
    "  HP: [hypothesis]\n",
    "- Make your hypotheses general enough to apply to new tweet pairs.\n",
    "\n",
    "### Part 2: Hypothesis-Based Inference\n",
    "Using the hypotheses you just generated, apply them to a given pair of tweets.\n",
    "- Predict which tweet will be retweeted more based on the learned patterns.\n",
    "- Answer in the format:\n",
    "  **Final answer: the _ tweet** (where `_` is either `first` or `second`)\n",
    "\n",
    "Think step by step:\n",
    "1. Can your hypothesis apply to the tweets?\n",
    "2. Analyze the textual differences.\n",
    "3. Decide which tweet is more likely to be retweeted.\n",
    "4. Provide your final prediction.\n",
    "\n",
    "\n",
    "## INPUT\n",
    "- First tweet: {first_tweet}\n",
    "- Second tweet: {second_tweet}\n",
    "\n",
    "## OUTPUT\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## INSTRUCTION\n",
      "You are a social media expert. Your task has two parts:\n",
      "\n",
      "### Part 1: Hypothesis Generation\n",
      "Given a set of tweet observations, you will generate hypotheses that are useful for predicting which tweet out of a pair will be retweeted more.\n",
      "- Each tweet pair is posted by the same user and contains similar content with slight wording differences.\n",
      "- Focus on these wording differences.\n",
      "- Please generate 1 hypotheses in the format:\n",
      "  HP: [hypothesis]\n",
      "- Make your hypotheses general enough to apply to new tweet pairs.\n",
      "\n",
      "### Part 2: Hypothesis-Based Inference\n",
      "Using the hypotheses you just generated, apply them to a given pair of tweets.\n",
      "- Predict which tweet will be retweeted more based on the learned patterns.\n",
      "- Answer in the format:\n",
      "  **Final answer: the _ tweet** (where `_` is either `first` or `second`)\n",
      "\n",
      "Think step by step:\n",
      "1. Can your hypothesis apply to the tweets?\n",
      "2. Analyze the textual differences.\n",
      "3. Decide which tweet is more likely to be retweeted.\n",
      "4. Provide your final prediction.\n",
      "\n",
      "\n",
      "## INPUT\n",
      "- First tweet: How Great is Our God [essential collection] released today...just wish i had room to add a few more:) http://t.co/JXGbJucz\n",
      "- Second tweet: the (world edition) of How Great is Our God is possibly the best thing i'll be a part of musically...ever http://t.co/JXGbJucz\n",
      "\n",
      "## OUTPUT\n",
      "HP: The second tweet expresses a stronger enthusiasm and personal involvement, which typically increases the likelihood of being retweeted.\n",
      "**Final answer: the second tweet** To solve this problem, let's go through the steps systematically:\n",
      "\n",
      "### Step 1: Can the Hypothesis Apply to the Tweets?\n",
      "Both tweets mention \"How Great is Our God\" as an essential release, point to a specific link, and express enthusiasm about it. However, there are significant differences in the way the enthusiasm is expressed.\n",
      "\n",
      "### Step 2: Analyze the Textual Differences\n",
      "- **First Tweet**: \n",
      "  - \"How Great is Our God [essential collection] released today...just wish i had room to add a few more:) \"\n",
      "  - The first tweet uses a somewhat casual and slightly sarcastic tone with the phrase \"just wish i had room to add a few more\". It also includes a colon at the end, which might indicate a pause or reflection.\n",
      "  \n",
      "- **Second Tweet**: \n",
      "  -\n"
     ]
    }
   ],
   "source": [
    "first_tweet = '''How Great is Our God [essential collection] released today...just wish i had room to add a few more:) http://t.co/JXGbJucz'''\n",
    "second_tweet = '''the (world edition) of How Great is Our God is possibly the best thing i'll be a part of musically...ever http://t.co/JXGbJucz'''\n",
    "\n",
    "\n",
    "formatted_prompt = prompt.format(first_tweet=first_tweet, second_tweet=second_tweet)\n",
    "\n",
    "# Generate hypotheses\n",
    "hypotheses = llm(formatted_prompt, \n",
    "    max_new_tokens=200, \n",
    "    num_return_sequences=1,\n",
    "    temperature=0.9, \n",
    "    do_sample=True)\n",
    "print(hypotheses[0]['generated_text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
